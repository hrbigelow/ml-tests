A Matrix Multiplication view of Convolutions

    Convolutions and Deconvolutions are somewhat confusing to me, and I've found
    this visualization useful for sorting out all of the variations.  I hope you
    find it useful as well!

    Suppose you have a 1D convolution filter:

    [filter.png]
    [1D convolution filter]

    Each color represents a distinct value.  The value could be a scalar or a
    matrix.  For the purposes of this article, we just consider it to be an
    abstract "element" that can be multiplied with an input element.

    Using the same color-coded values (with gray representing zero), here is
    picture of matrix multiply style of convolution using this filter.

    [mat_s1_ph0_inv0_lp0_rp0_d0.png]
    [Stride 1, No padding, Green reference element]
    [F.conv1d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1)]

    Because it is square, the matrix multiplication produces an output the same
    size as the input.  Due to the lack of padding, the first two and last two
    positions are "invalid".  The output shows zero-valued placeholders in these
    positions.  But the one-to-one correspondence between input and output is
    clear.  This is helpful to distinguish between edge effects, stride, and
    inverse stride, as we will see below. 

    Notice that the green filter element appears on the matrix diagonal.  I call it
the filter's "reference element".  With a choice of reference element, the
"filter position" now means "the input element covered by the reference
element".  Thus, the output of a convolution is now in one-to-one
correspondence with the input elements.  Stride and padding and dilation don't
affect this correspondence, but do define *which* outputs are considered valid.

Here are more examples.  These are all generated with [this script][
https://github.com/hrbigelow/ml-tests/blob/master/conv.py].  The script
generates each matrix based on the given filter and convolution parameters.  It
then tests the result of a convolution using PyTorch's torch.nn.functional
conv1d and conv_transpose1d and the matrix multiply approach outlined here.


[mat_s1_ph0_inv0_lp2_rp1_d0.png]
[Stride 1, Left padding 2, Right padding 1]
[F.conv1d(input, weight, bias=None, stride=1, padding=2, dilation=1, groups=1)]

Here we see the effects of a Left padding of 2, and Right padding of 1.  This
means the filter is allowed to hang off the left end by two positions and right
end by one position.  The effect is to make three more positions valid.  Note
that the one-to-one correspondence of the central elements is undisturbed by
this.

[mat_s2_ph0_inv0_lp2_rp1_d0.png]
[Stride 2, Left padding 2, Right padding 1]
[F.conv1d(input, weight, bias=None, stride=2, padding=2, dilation=1, groups=1)]

This is the same as the previous matrix, but now with stride 2.  The only
change is that every other matrix row is zeros, and corresponding output
position is invald. 

[mat_s2_ph1_inv0_lp2_rp1_d0.png]
[Stride 2, Left padding 2, Right padding 1, Phase 1]
[No matching commnand]

Note that with stride > 1, there is an implicit choice of phase that must be
made.  The previous picture was phase 0.  Here is the same matrix with phase 1.

[mat_s1_ph0_inv0_lp0_rp0_d1.png]
[Stride 1, No padding, Dilation 1]
[F.conv1d(input, weight, bias=None, stride=2, padding=0, dilation=2, groups=1)]

Going back to the basic matrix with stride 1 and no padding, here is an
illustration of dilation.  Note that the kernel is wider, so the lack of
padding means more invalid positions on the ends.

[mat_s2_ph0_inv1_lp0_rp0_d0.png]
[Stride 1/2, No padding]
[F.conv_transpose1d(input, weight, bias=None, stride=2, padding=4, output_padding=0, groups=1, dilation=1)]

Finally, here is an example of the so-called fractionally strided convolution,
or deconvolution.  The reciprocal of the stride is applied to the input,
dilating it with zero values.  Also, The effect is to up-sample.  This is only meant
to illustrate how matrix cells and filter values combine with input, and how
the input corresponds to the output.  The relationship between a convolution
and its "matching" deconvolution is not shown here. 


The matching torch function calls are shown.  Note that torch counts a
'non-dilation' as dilation=1.  Also, it doesn't allow different settings for
left and right padding.  Finally, it *does* allow having padding up to the size
of the filter minus 1.  This allows the filter to cover more positions than the
input length.  For the purposes of this comparison, we only use paddings that
are less than half the length of the filter.  This ensures the filter will
cover no more positions than the number of input elements.



